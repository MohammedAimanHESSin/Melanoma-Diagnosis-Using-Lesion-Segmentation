{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom skimage.transform import resize\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping ,ReduceLROnPlateau\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout \nimport os\nfrom keras.applications.vgg16 import preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-02T15:05:28.486907Z","iopub.execute_input":"2022-01-02T15:05:28.487224Z","iopub.status.idle":"2022-01-02T15:05:34.188636Z","shell.execute_reply.started":"2022-01-02T15:05:28.487143Z","shell.execute_reply":"2022-01-02T15:05:34.187898Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_images_path = \"../input/assi4-dataset/resized_training/resized_training\" \ntrain_mask_path = \"../input/assi4-dataset/resized_training_mask/resized_training_mask\"\ntrain_metadata_path = \"../input/assi4-dataset/ISIC-2017_Training_Data_metadata.csv\"\n\nval_images_path = \"../input/assi4-dataset/resized_val/resized_val\"\nval_mask_path = \"../input/assi4-dataset/resized_val_mask/resized_val_mask\"\nval_metadata_path = \"../input/assi4-dataset/ISIC-2017_Validation_Data_metadata.csv\"\n\ntest_images_path = \"../input/assi4-dataset/resized_test\"\ntest_mask_path = \"../input/assi4-dataset/resized_test_mask/resized_test_mask\"\ntest_metadata_path = \"../input/assi4-dataset/ISIC-2017_Test_v2_Data_metadata.csv\"\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:34.190095Z","iopub.execute_input":"2022-01-02T15:05:34.190328Z","iopub.status.idle":"2022-01-02T15:05:34.194258Z","shell.execute_reply.started":"2022-01-02T15:05:34.190295Z","shell.execute_reply":"2022-01-02T15:05:34.193606Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def read_metadata(path):\n    metadata_Dataframe = pd.read_csv(path)\n    metadata_Dataframe.head()\n    return metadata_Dataframe","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:34.195834Z","iopub.execute_input":"2022-01-02T15:05:34.196222Z","iopub.status.idle":"2022-01-02T15:05:34.208180Z","shell.execute_reply.started":"2022-01-02T15:05:34.196186Z","shell.execute_reply":"2022-01-02T15:05:34.207485Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_images_from_folder(path,ids):\n    images = []\n    for imageId in ids:\n        images.append( cv2.resize(cv2.imread(os.path.join(path,imageId+'.jpg')), (256,256), interpolation = cv2.INTER_AREA) )\n    print('images load done')\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:34.211564Z","iopub.execute_input":"2022-01-02T15:05:34.211758Z","iopub.status.idle":"2022-01-02T15:05:34.218357Z","shell.execute_reply.started":"2022-01-02T15:05:34.211734Z","shell.execute_reply":"2022-01-02T15:05:34.217728Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_masks_from_folder(path,ids):\n    images = []\n    for imageId in ids:\n        img = cv2.imread(os.path.join(path,imageId+'.png'))\n        img = tf.image.resize(img, (256,256), method='nearest')\n        img = tf.image.rgb_to_grayscale(img)/255\n        images.append(img)\n    print('images load done')\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:34.219640Z","iopub.execute_input":"2022-01-02T15:05:34.220010Z","iopub.status.idle":"2022-01-02T15:05:34.227120Z","shell.execute_reply.started":"2022-01-02T15:05:34.219973Z","shell.execute_reply":"2022-01-02T15:05:34.226364Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_metadata = read_metadata(train_metadata_path)\nval_metadata = read_metadata(val_metadata_path)\n#test_metadata = read_metadata(test_metadata_path)\ntrain_images_ids = train_metadata['image_id']\nval_images_ids = val_metadata['image_id']\n#test_images_ids = test_metadata['image_id']\n\n\ntrain_images = load_images_from_folder(train_images_path,train_images_ids)\nval_images = load_images_from_folder(val_images_path,val_images_ids)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:34.228356Z","iopub.execute_input":"2022-01-02T15:05:34.228635Z","iopub.status.idle":"2022-01-02T15:05:58.633615Z","shell.execute_reply.started":"2022-01-02T15:05:34.228598Z","shell.execute_reply":"2022-01-02T15:05:58.632846Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_masks = load_masks_from_folder(train_mask_path,train_images_ids)\nval_masks = load_masks_from_folder(val_mask_path,val_images_ids)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:05:58.634919Z","iopub.execute_input":"2022-01-02T15:05:58.635321Z","iopub.status.idle":"2022-01-02T15:06:28.319179Z","shell.execute_reply.started":"2022-01-02T15:05:58.635283Z","shell.execute_reply":"2022-01-02T15:06:28.317539Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.imshow(train_images[1])\nplt.figure()\nplt.imshow(train_masks[1])\nplt.figure()\nplt.imshow(val_images[1])\nplt.figure()\nplt.imshow(val_masks[1])\ntrain_images.shape\nval_masks.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:28.320335Z","iopub.execute_input":"2022-01-02T15:06:28.320597Z","iopub.status.idle":"2022-01-02T15:06:29.058501Z","shell.execute_reply.started":"2022-01-02T15:06:28.320561Z","shell.execute_reply":"2022-01-02T15:06:29.057704Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(patience=5, verbose=1),\n    #ReduceLROnPlateau(factor=0.8, patience=2, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('tgs-salt-model-v1.h5', verbose=1, save_best_only=True)\n]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:29.059963Z","iopub.execute_input":"2022-01-02T15:06:29.060226Z","iopub.status.idle":"2022-01-02T15:06:29.064892Z","shell.execute_reply.started":"2022-01-02T15:06:29.060192Z","shell.execute_reply":"2022-01-02T15:06:29.064232Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\ndef jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\n\ndef iou_coef(y_true, y_pred, smooth=10):\n    print(y_true)\n    print(y_pred)\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef jaccard_distance_loss(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef jacard_coef_loss(y_true, y_pred):\n    return -iou_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:29.067416Z","iopub.execute_input":"2022-01-02T15:06:29.068219Z","iopub.status.idle":"2022-01-02T15:06:29.077992Z","shell.execute_reply.started":"2022-01-02T15:06:29.068180Z","shell.execute_reply":"2022-01-02T15:06:29.077251Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"raw","source":"def IoU_loss(y_true, y_pred):\n    nb_classes = K.int_shape(y_pred)[-1]\n    iou = []\n    pred_pixels = K.argmax(y_pred, axis=-1)\n    for i in range(0, nb_classes):  # exclude first label (background) and last label (void)\n        true_labels = K.equal(y_true[:, :, 0], i)\n        pred_labels = K.equal(pred_pixels, i)\n        inter = tf.cast(true_labels & pred_labels, dtype=tf.int32)\n        union = tf.cast(true_labels | pred_labels, dtype=tf.int32)\n        legal_batches = K.sum(tf.cast(true_labels, dtype=tf.int32), axis=1) > 0\n        ious = K.sum(inter, axis=1) / K.sum(union, axis=1)\n        iou.append(K.mean(ious[legal_batches]))\n\n    iou = tf.stack(iou)\n    legal_labels = ~tf.math.is_nan(iou)\n    iou = iou[legal_labels]\n    return K.mean(iou)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:51:59.651182Z","iopub.execute_input":"2022-01-01T21:51:59.651546Z","iopub.status.idle":"2022-01-01T21:51:59.660508Z","shell.execute_reply.started":"2022-01-01T21:51:59.651509Z","shell.execute_reply":"2022-01-01T21:51:59.659814Z"}}},{"cell_type":"raw","source":"#First Branch (Image)\ninputImg = tf.keras.layers.Input((256,256,3) , name='image')\ns = Lambda(lambda x: x / 255)(inputImg)   \nc1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (s)\nc1 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c1)\np1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c1)\n#-------------------------------------------------------------------------------------\nc2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (p1)\nc2 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c2)\np2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c2)\n#-------------------------------------------------------------------------------------\nc3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (p2)\nc3 = tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c3)\nc7 = tf.keras.layers.Conv2D(265, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c3)\np3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c7)\n#-------------------------------------------------------------------------------------\nc4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (p3)\nc4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c4)\nc4 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n#-------------------------------------------------------------------------------------\nc5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (p4)\nc5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c5)\nc5 = tf.keras.layers.Conv2D(512, (3, 3), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c5)\np5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c5)\n#-------------------------------------------------------------------------------------\nc5 = tf.keras.layers.Conv2D(4096, (7, 7), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (p5)\nc5 = tf.keras.layers.Conv2D(4096, (7, 7), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c5)\nc6 = tf.keras.layers.Conv2D(2, (1, 1), kernel_initializer='he_normal', activation='relu' , padding=\"same\") (c5)\n'''\nf1 = tf.keras.layers.Flatten()(p13)\ndense1 = tf.keras.layers.Dense(4096, activation='relu') (f1)\ndense2 = tf.keras.layers.Dense(4096, activation='relu') (dense1)\n'''\n'''\n#Second Branch (age)\ninput_metadata = tf.keras.layers.Input((None,1,2), name='metadata')\nc1 = tf.keras.layers.Conv1D(2, 1,strides=1, activation='relu' , padding=\"same\")(input_metadata)\nc2 = tf.keras.layers.Conv1D(2, 1,strides=1, activation='relu' , padding=\"same\")(c1)\nc4 = tf.keras.layers.Conv1D(2, 1,strides=1, activation='relu' , padding=\"same\")(c2)\nc4 = tf.keras.layers.UpSampling2D(size=(1, 2))(c4)\n\n#Combine\ncombinedBranches = concatenate([c3, c4])\n'''\nc1Dec = tf.keras.layers.Conv2DTranspose(32, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c6)\nc2Dec = tf.keras.layers.Conv2DTranspose(64, (3, 3),strides=(4, 4), activation='relu', padding=\"same\") (c1Dec)\nc3Dec = tf.keras.layers.Conv2DTranspose(2, (3, 3),strides=(4, 4), activation='relu', padding=\"same\") (c2Dec)\n#c1Dec = tf.keras.layers.UpSampling2D(size=(32, 32))(c15)\n\nfinalOutput = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\",activation='sigmoid') (c3Dec)\n\nmodel = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\n\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.1, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[iou_coef])\n'''\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.1, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'), loss = [jacard_coef_loss], metrics = [iou_coef])\n'''\n'''\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\n'''\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T14:31:23.368719Z","iopub.execute_input":"2022-01-02T14:31:23.368970Z","iopub.status.idle":"2022-01-02T14:31:24.107853Z","shell.execute_reply.started":"2022-01-02T14:31:23.368937Z","shell.execute_reply":"2022-01-02T14:31:24.107161Z"}}},{"cell_type":"markdown","source":"# Pretrained VGG16","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG19(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(256, 256, 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top.\nbase_model.trainable = False\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:29.079438Z","iopub.execute_input":"2022-01-02T15:06:29.079766Z","iopub.status.idle":"2022-01-02T15:06:30.208177Z","shell.execute_reply.started":"2022-01-02T15:06:29.079730Z","shell.execute_reply":"2022-01-02T15:06:30.207444Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"inputImg = tf.keras.layers.Input((256,256,3) , name='image')\ns = Lambda(lambda x: x / 255)(inputImg)   \nx = base_model(inputImg,training=False)\n#tf.keras.layers.Flatten()(model.layers[-1].output)\nimageModelOutput = tf.keras.layers.GlobalAveragePooling2D()(x)\nb1 = tf.keras.layers.BatchNormalization()(imageModelOutput)\nd1 = tf.keras.layers.Dense(256, activation='relu' )(b1)\nd1 = tf.keras.layers.Dense(512, activation='relu' )(d1)\nd1 = tf.keras.layers.Dense(256, activation='relu' )(d1)\nd1 = tf.keras.layers.Dense(512, activation='relu' )(d1)\nd1 = tf.keras.layers.Dense(256, activation='relu' )(d1)\nreshaped = tf.keras.layers.Reshape((16, 16,1), input_shape=(256,)) (d1)\nc1Dec = tf.keras.layers.Conv2DTranspose(16, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (reshaped)\nc2Dec = tf.keras.layers.Conv2DTranspose(32, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c1Dec)\nc3Dec = tf.keras.layers.Conv2DTranspose(64, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c2Dec)\nc4Dec = tf.keras.layers.Conv2DTranspose(256, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c3Dec)\nc4Dec = tf.keras.layers.Conv2DTranspose(512, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c3Dec)\nc4Dec = tf.keras.layers.Conv2DTranspose(1024, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c3Dec)\nc4Dec = tf.keras.layers.Conv2DTranspose(1024, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c3Dec)\nfinalOutput = tf.keras.layers.Conv2D(1, (1, 1),activation='sigmoid') (c4Dec)\n\nmodel = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n    loss=[jacard_coef_loss],\n    metrics=[iou_coef])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:30.209504Z","iopub.execute_input":"2022-01-02T15:06:30.209758Z","iopub.status.idle":"2022-01-02T15:06:30.436624Z","shell.execute_reply.started":"2022-01-02T15:06:30.209725Z","shell.execute_reply":"2022-01-02T15:06:30.435864Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# U-NET","metadata":{}},{"cell_type":"raw","source":"inputImg = tf.keras.layers.Input((256,256,3) , name='image')\ns = Lambda(lambda x: x / 255)(inputImg)   \nc1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n#c1 = Dropout(0.1)(c1)\nc1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = MaxPooling2D((2, 2))(c1)\n\nc2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n#c2 = Dropout(0.1)(c2)\nc2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = MaxPooling2D((2, 2))(c2)\n\nc3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n#c3 = Dropout(0.2)(c3)\nc3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = MaxPooling2D((2, 2))(c3)\n\nc4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n#c4 = Dropout(0.2)(c4)\nc4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = MaxPooling2D(pool_size=(2, 2))(c4)\n\nc5 = Conv2D(521, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n#c5 = Dropout(0.3)(c5)\nc5 = Conv2D(521, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n#Expansive path \nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n#c6 = Dropout(0.2)(c6)\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n#c7 = Dropout(0.2)(c7)\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n#c8 = Dropout(0.1)(c8)\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n#c9 = Dropout(0.1)(c9)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n\nfinalOutput = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n\nmodel = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[iou_coef])\n#model.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T12:10:57.169154Z","iopub.execute_input":"2022-01-02T12:10:57.169572Z","iopub.status.idle":"2022-01-02T12:10:57.401850Z","shell.execute_reply.started":"2022-01-02T12:10:57.169537Z","shell.execute_reply":"2022-01-02T12:10:57.401170Z"}}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsession = tf.compat.v1.Session(config=config)\nK.set_session(session)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:30.437864Z","iopub.execute_input":"2022-01-02T15:06:30.438551Z","iopub.status.idle":"2022-01-02T15:06:30.451682Z","shell.execute_reply.started":"2022-01-02T15:06:30.438511Z","shell.execute_reply":"2022-01-02T15:06:30.450135Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"'''\nresults = model.fit({'image': train_images, 'metadata' : train_metadata[[\"age_approximate\", \"sex\"]][0:100].to_numpy(dtype=np.float)}, train_masks, batch_size=32, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images, 'metadata': val_metadata[[\"age_approximate\", \"sex\"]][0:100].to_numpy(dtype=np.float)}, val_masks))\n'''\nprepared_images = preprocess_input(train_images)\n#prepared_images = preprocess_input(train_masks)\nprepared_images = preprocess_input(val_images)\n#prepared_images = preprocess_input(val_masks)\nresults = model.fit({'image': train_images}, train_masks, batch_size=16, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:06:30.453188Z","iopub.execute_input":"2022-01-02T15:06:30.453490Z","iopub.status.idle":"2022-01-02T15:32:41.771486Z","shell.execute_reply.started":"2022-01-02T15:06:30.453454Z","shell.execute_reply":"2022-01-02T15:32:41.770744Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Visualize results","metadata":{}},{"cell_type":"code","source":"loss = results.history['loss']\nval_loss = results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:32:41.773215Z","iopub.execute_input":"2022-01-02T15:32:41.773709Z","iopub.status.idle":"2022-01-02T15:32:41.980342Z","shell.execute_reply.started":"2022-01-02T15:32:41.773672Z","shell.execute_reply":"2022-01-02T15:32:41.979647Z"},"trusted":true},"execution_count":15,"outputs":[]}]}